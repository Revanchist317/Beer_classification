{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379eb52e-ffe3-4d78-9b3c-6811b9a43a80",
   "metadata": {},
   "source": [
    "Notes \n",
    "\n",
    "This challegen consists of multi-class classification problem (5 targets) and it concerns images of beer (glass bottles). The goal is to assign the correct beer brand to each image (Chimay Blue, Orval, Rochefort 10, Westmalle Tripel and Westvleteren 12, 0-4, respectively).\n",
    "\n",
    "The inital idea is to train the model on the training data and test the performance on the eval data (that's our testing set). Once that's done, and we're happy with out model, we should train it on ALL available data of course, and only then deploy it to GCP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e625a7-59d2-4ce4-a5af-62dc72460415",
   "metadata": {},
   "source": [
    "Ideas \n",
    "\n",
    "The task that lies before us is a fairly straightforward multiclass classification with images. The obvious solution here is to use a CNN. We can either build our own, or perhaps use a pre-trained model. I think transfer learning theory may be quite useful here. Additionally, image augmentation could be useful to improve the generalisation of the model. Data are already normalised to begin with \n",
    "\n",
    "Update #1 \\\n",
    "My constructed CNN seems to work quite well, adam optimiser appears to be the way to go, and batch siez of 10 is ideal. \n",
    "I also checked and what made this challenge easier is not having any obvious class imbalances, there are about 100 photos of beer per category (class-weighting, over/under-sampling, or some preferential data augmentation not necessary).\n",
    "\n",
    "Update #2 \\\n",
    "Leveraged transfer learning theory with VGG16 - works perfectly, better than my model. Set all weights within to untrainable. I also created a figure with the loss - very good convergence without apparent overfitting. \n",
    "\n",
    "Update #3 \\\n",
    "I implemented data augmentation, I added this to the task.py and task-final.py. I could add it to model.py, but this works fine\n",
    "\n",
    "Final update \\\n",
    "VGG16 pre-trained network with data augmentation and 120 epochs (trained in PyCharm on a different laptop with Nvidia, 4 times faster). The final loss was quite smooth though, which I'm very pleased with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7316450-4c15-41d1-acaf-e8c3c49875d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking the JSON file works corretly \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff166b7f-2075-4137-84d2-c2ccd019da34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bytes'])\n"
     ]
    }
   ],
   "source": [
    "with open('check_deployed_model/test.json') as f:\n",
    "    d = json.load(f)\n",
    "    print(d[\"instances\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7fd25-6c00-4813-bb3a-580627557af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai endpoints predict ID \\\n",
    "    --project=PROJECT_ID  \\\n",
    "    --region=europe-west1 \\\n",
    "    --json-request=check_deployed_model/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535678e9-9fc7-4c40-81f5-38287d011657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"output/exported_model\"\n",
    "loaded_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39d6cc4-720c-4578-8751-4321ae0514ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction (*, inputs: TensorSpec(shape=(None,), dtype=tf.string, name='inputs')) -> Dict[['output_1', TensorSpec(shape=(None, 5), dtype=tf.float32, name='output_1')], ['output_0', TensorSpec(shape=(None,), dtype=tf.int64, name='output_0')]] at 0x164504D10>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "909b4bf9-2022-442e-b75d-ce72ae20230d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.4026 - loss: 2.9809\n",
      "Epoch 2/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8486 - loss: 0.5482\n",
      "Epoch 3/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9492 - loss: 0.1297\n",
      "Epoch 4/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9807 - loss: 0.0441\n",
      "Epoch 5/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 6/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 7/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 8/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 9/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 10/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.3926e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 12/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.5845e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.2092e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.9461e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.7131e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.3742e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.3927e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 4.4247e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.2053e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.5195e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.8380e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.3683e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.6350e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.7539e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.4960e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 3.2535e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.7846e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1851e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.3424e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.6498e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1748e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.3349e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1331e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.8187e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.4137e-04\n",
      "Epoch 36/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.0695e-04\n",
      "Epoch 37/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.3076e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 8.2924e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.8916e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.4583e-05\n",
      "Figure(640x480)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7s/step - accuracy: 0.9032 - loss: 0.3530\n"
     ]
    }
   ],
   "source": [
    "!python3 -m trainer.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e205c0c3-f6bc-484c-9f31-a5c4ca5f9644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/model.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"Model to classify draft beers\n",
    "\n",
    "This file contains all the model information: the training steps, the batch\n",
    "size and the model itself.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_batch_size():\n",
    "    \"\"\"Returns the batch size that will be used by your solution.\n",
    "    It is recommended to change this value.\n",
    "    \"\"\"\n",
    "    return 10\n",
    "\n",
    "def get_epochs():\n",
    "    \"\"\"Returns number of epochs that will be used by your solution.\n",
    "    It is recommended to change this value.\n",
    "    \"\"\"\n",
    "    return 120\n",
    "\n",
    "def solution(input_layer):\n",
    "    \"\"\"Returns a compiled model.\n",
    "\n",
    "    This function is expected to return a model to identity the different beers.\n",
    "    The model's outputs are expected to be probabilities for the classes and\n",
    "    and it should be ready for training.\n",
    "    The input layer specifies the shape of the images. The preprocessing\n",
    "    applied to the images is specified in data.py.\n",
    "\n",
    "    Add your solution below.\n",
    "\n",
    "    Parameters:\n",
    "        input_layer: A tf.keras.layers.InputLayer() specifying the shape of the input.\n",
    "            RGB colored images, shape: (width, height, 3)\n",
    "    Returns:\n",
    "        model: A compiled model\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Using the VGG16, pre-trained network based on ImageNet (developed at Oxford, seems appropraite)\n",
    "\n",
    "    # The easiest thing to do here is to hardcode the image size. Terrible, but ideal for the purposes of this challenge\n",
    "    img_size = [160, 160]\n",
    "\n",
    "    # Make sure to exclude the top layer, we can do this ourselves \n",
    "    ptm = tf.keras.applications.vgg16.VGG16(\n",
    "        input_shape=img_size + [3],\n",
    "        weights='imagenet',\n",
    "        include_top=False)\n",
    "\n",
    "    # Avoid retraining the weights, the top will so\n",
    "    ptm.trainable = False\n",
    "\n",
    "    # Construct the top layers \n",
    "    i = ptm.input # I'm being a bit cheeky here and using the ptm input layer, not the one provided by the code \n",
    "    x = tf.keras.layers.Flatten()(ptm.output)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Hardcode the number of beers\n",
    "    x = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    # There are 63 steps per epoch, 120 epochs, 7560 steps, which means a decrease of 28 % \n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=1000,  \n",
    "            decay_rate=0.96,   # 4% decrease every 1000 steps\n",
    "            staircase=True)\n",
    "\n",
    "    # Finalise and compile the model with the learning rate scheduler, include accuracy \n",
    "    model = tf.keras.models.Model(i, x)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adc3312d-c003-4124-aa2e-cf9bf0b79702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/task.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"Train and evaluate the model\n",
    "\n",
    "This file trains the model upon the training data and evaluates it with\n",
    "the eval data.\n",
    "It uses the arguments it got via the gcloud command.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import trainer.data as data\n",
    "import trainer.model as model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train_model(params):\n",
    "    \"\"\"The function gets the training data from the training folder,\n",
    "    the evaluation data from the eval folder and trains your solution\n",
    "    from the model.py file with it.\n",
    "\n",
    "    Parameters:\n",
    "        params: parameters for training the model\n",
    "    \"\"\"\n",
    "    (train_data, train_labels) = data.create_data_with_labels(\"data/train/\")\n",
    "    (eval_data, eval_labels) = data.create_data_with_labels(\"data/eval/\")\n",
    "\n",
    "    img_shape = train_data.shape[1:]\n",
    "    input_layer = tf.keras.Input(shape=img_shape, name='input_image')\n",
    "\n",
    "    ml_model = model.solution(input_layer)\n",
    "\n",
    "    if ml_model is None:\n",
    "        print(\"No model found. You need to implement one in model.py\")\n",
    "    else:\n",
    "        r = ml_model.fit(train_data, train_labels,\n",
    "                     batch_size=model.get_batch_size(),\n",
    "                     epochs=model.get_epochs())\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize = (10,10))\n",
    "        plt.plot(r.history['loss'], label='train loss')\n",
    "        plt.plot(r.history['accuracy'], label='accuracy')\n",
    "        plt.legend()\n",
    "        fig.savefig(\"V2_ML6.svg\")\n",
    "        \n",
    "        ml_model.evaluate(eval_data, eval_labels, verbose=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    tf_logger = logging.getLogger(\"tensorflow\")\n",
    "    tf_logger.setLevel(logging.INFO)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(tf_logger.level // 10)\n",
    "\n",
    "    train_model(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21114145-9824-40e0-9f05-5c3d095111f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer/final_task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer/final_task.py\n",
    "# %load trainer/final_task.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"Train and export the model\n",
    "\n",
    "This file trains the model upon all data with the arguments it got via\n",
    "the gcloud command.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import trainer.data as data\n",
    "import trainer.model as model\n",
    "\n",
    "\n",
    "def prepare_prediction_image(image_str_tensor):\n",
    "    \"\"\"Prepare an image tensor for prediction.\n",
    "    Takes a string tensor containing a binary jpeg image and returns\n",
    "    a tensor object of the image with dtype float32.\n",
    "\n",
    "    Parameters:\n",
    "        image_str_tensor: a tensor containing a binary jpeg image as a string\n",
    "    Returns:\n",
    "        image: A tensor representing an image.\n",
    "    \"\"\"\n",
    "    image_str_tensor = tf.cast(image_str_tensor, tf.string)\n",
    "    image = tf.image.decode_jpeg(image_str_tensor, channels=3)\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = data.preprocess_image(image)\n",
    "    return image\n",
    "\n",
    "def prepare_prediction_image_batch(image_str_tensor):\n",
    "    \"\"\"Prepare a batch of images for prediction.\"\"\"\n",
    "    return tf.map_fn(prepare_prediction_image, image_str_tensor,\n",
    "                     dtype=tf.float32)\n",
    "\n",
    "def export_model(ml_model, export_dir, model_dir='exported_model'):\n",
    "    \"\"\"Prepare model for strings representing image data and export it.\n",
    "\n",
    "    Before the model is exported the initial layers of the model need to be\n",
    "    adapted to handle prediction of images contained in JSON files.\n",
    "\n",
    "    Parameters:\n",
    "        ml_model: A compiled model\n",
    "        export_dir: A string specifying the\n",
    "        model_dir: A string specifying the name of the directory to\n",
    "            which the model is written.\n",
    "    \"\"\"\n",
    "    prediction_input = tf.keras.Input(\n",
    "        dtype=tf.string, name='bytes', shape=())\n",
    "    prediction_output = tf.keras.layers.Lambda(\n",
    "        prepare_prediction_image_batch)(prediction_input)\n",
    "\n",
    "    prediction_output = ml_model(prediction_output)\n",
    "    prediction_output = tf.keras.layers.Lambda(\n",
    "        lambda x: x, name='PROBABILITIES')(prediction_output)\n",
    "    prediction_class = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.argmax(x, 1), name='CLASSES')(prediction_output)\n",
    "    \n",
    "    ml_model = tf.keras.models.Model(prediction_input, outputs=[prediction_class, prediction_output])\n",
    "\n",
    "    model_path = Path(export_dir) / model_dir\n",
    "    if model_path.exists():\n",
    "        timestamp = datetime.now().strftime(\"-%Y-%m-%d-%H-%M-%S\")\n",
    "        model_path = Path(str(model_path) + timestamp)\n",
    "\n",
    "    tf.saved_model.save(ml_model, str(model_path))\n",
    "\n",
    "def train_and_export_model(params):\n",
    "    \"\"\"The function gets the training data from the training folder and\n",
    "    the eval folder.\n",
    "    Your solution in the model.py file is trained with this training data.\n",
    "    The evaluation in this method is not important since all data was already\n",
    "    used to train.\n",
    "\n",
    "    Parameters:\n",
    "        params: Parameters for training and exporting the model\n",
    "    \"\"\"\n",
    "    (train_data, train_labels) = data.create_data_with_labels(\"data/train/\")\n",
    "    (eval_data, eval_labels) = data.create_data_with_labels(\"data/eval/\")\n",
    "\n",
    "    train_data = np.append(train_data, eval_data, axis=0)\n",
    "    train_labels = np.append(train_labels, eval_labels, axis=0)\n",
    "\n",
    "    img_shape = train_data.shape[1:]\n",
    "    input_layer = tf.keras.Input(shape=img_shape, name='input_image')\n",
    "\n",
    "    ml_model = model.solution(input_layer)\n",
    "\n",
    "    # Here we implement the data augmentation generator\n",
    "    data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=20,         # Randomly rotate images by 20 degrees\n",
    "        width_shift_range=0.2,     # Randomly shift images horizontally\n",
    "        height_shift_range=0.2,    # Randomly shift images vertically\n",
    "        shear_range=0.2,           # Randomly apply shearing, I think this is in radians \n",
    "        zoom_range=0.1,            # Randomly zoom in on images\n",
    "        horizontal_flip=True,      # Randomly flip images horizontally\n",
    "        fill_mode='nearest'        # Fill in new pixels after transformations\n",
    "    )\n",
    "\n",
    "    train_gen = data_augmentation.flow(train_data, train_labels, batch_size=model.get_batch_size())\n",
    "    \n",
    "    ml_model.fit(train_gen,\n",
    "                 batch_size=model.get_batch_size(),\n",
    "                 epochs=model.get_epochs())\n",
    "    export_model(ml_model, export_dir=params.job_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        type=str,\n",
    "        default='output',\n",
    "        help='directory to store checkpoints'\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    tf_logger = logging.getLogger(\"tensorflow\")\n",
    "    tf_logger.setLevel(logging.INFO)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(tf_logger.level // 10)\n",
    "\n",
    "    train_and_export_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178a7c81-85f8-4f71-8f82-1405e52df339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/revanhome/anaconda3/envs/tf/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.2868 - loss: 5.3194\n",
      "Epoch 2/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.6188 - loss: 0.9569\n",
      "Epoch 3/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.7205 - loss: 0.7659\n",
      "Epoch 4/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7747 - loss: 0.6004\n",
      "Epoch 5/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - accuracy: 0.8097 - loss: 0.4999\n",
      "Epoch 6/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8571 - loss: 0.4242\n",
      "Epoch 7/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.8671 - loss: 0.3928\n",
      "Epoch 8/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.8796 - loss: 0.3623\n",
      "Epoch 9/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 4s/step - accuracy: 0.8712 - loss: 0.3842\n",
      "Epoch 10/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1043s\u001b[0m 21s/step - accuracy: 0.8740 - loss: 0.3697\n",
      "Epoch 11/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.8630 - loss: 0.3628\n",
      "Epoch 12/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.8457 - loss: 0.3793\n",
      "Epoch 13/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.8949 - loss: 0.3543\n",
      "Epoch 14/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9113 - loss: 0.2790\n",
      "Epoch 15/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.8804 - loss: 0.3112\n",
      "Epoch 16/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9067 - loss: 0.2398\n",
      "Epoch 17/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.8637 - loss: 0.3943\n",
      "Epoch 18/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9033 - loss: 0.2501\n",
      "Epoch 19/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9175 - loss: 0.2515\n",
      "Epoch 20/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9351 - loss: 0.2057\n",
      "Epoch 21/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8827 - loss: 0.3688\n",
      "Epoch 22/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9504 - loss: 0.1606\n",
      "Epoch 23/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 4s/step - accuracy: 0.9224 - loss: 0.2090\n",
      "Epoch 24/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.9518 - loss: 0.1469\n",
      "Epoch 25/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9437 - loss: 0.1923\n",
      "Epoch 26/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9399 - loss: 0.1825\n",
      "Epoch 27/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.9004 - loss: 0.2953\n",
      "Epoch 28/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.9244 - loss: 0.2006\n",
      "Epoch 29/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9349 - loss: 0.2008\n",
      "Epoch 30/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9478 - loss: 0.1519\n",
      "Epoch 31/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9143 - loss: 0.2597\n",
      "Epoch 32/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9232 - loss: 0.2055\n",
      "Epoch 33/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9451 - loss: 0.1622\n",
      "Epoch 34/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.9596 - loss: 0.1373\n",
      "Epoch 35/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.2510\n",
      "Epoch 36/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9275 - loss: 0.2058\n",
      "Epoch 37/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.9028 - loss: 0.2836\n",
      "Epoch 38/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9323 - loss: 0.1620\n",
      "Epoch 39/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9245 - loss: 0.2205\n",
      "Epoch 40/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9227 - loss: 0.1662\n",
      "Epoch 41/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9567 - loss: 0.1474\n",
      "Epoch 42/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9327 - loss: 0.2200\n",
      "Epoch 43/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9626 - loss: 0.1286\n",
      "Epoch 44/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1184\n",
      "Epoch 45/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.9441 - loss: 0.1529\n",
      "Epoch 46/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.9407 - loss: 0.1591\n",
      "Epoch 47/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9207 - loss: 0.1953\n",
      "Epoch 48/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - accuracy: 0.9344 - loss: 0.1558\n",
      "Epoch 49/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.9717 - loss: 0.1144\n",
      "Epoch 50/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.9631 - loss: 0.1264\n",
      "Epoch 51/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9737 - loss: 0.0957\n",
      "Epoch 52/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9594 - loss: 0.1257\n",
      "Epoch 53/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2s/step - accuracy: 0.9516 - loss: 0.1361\n",
      "Epoch 54/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9624 - loss: 0.1057\n",
      "Epoch 55/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9599 - loss: 0.1314\n",
      "Epoch 56/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 1s/step - accuracy: 0.9614 - loss: 0.1045\n",
      "Epoch 57/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9679 - loss: 0.0853\n",
      "Epoch 58/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 1s/step - accuracy: 0.9659 - loss: 0.1170\n",
      "Epoch 59/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.9579 - loss: 0.1071\n",
      "Epoch 60/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.9449 - loss: 0.1366\n",
      "Epoch 61/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9176 - loss: 0.2011\n",
      "Epoch 62/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1349\n",
      "Epoch 63/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1253\n",
      "Epoch 64/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.9748 - loss: 0.0821\n",
      "Epoch 65/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.9636 - loss: 0.1311\n",
      "Epoch 66/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.9802 - loss: 0.0756\n",
      "Epoch 67/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.9806 - loss: 0.0745\n",
      "Epoch 68/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.9687 - loss: 0.0903\n",
      "Epoch 69/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.9859 - loss: 0.0599\n",
      "Epoch 70/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.9588 - loss: 0.0961\n",
      "Epoch 71/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9647 - loss: 0.1218\n",
      "Epoch 72/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.9604 - loss: 0.0839\n",
      "Epoch 73/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2s/step - accuracy: 0.9646 - loss: 0.0942\n",
      "Epoch 74/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.9579 - loss: 0.1124\n",
      "Epoch 75/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9230 - loss: 0.2037\n",
      "Epoch 76/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.9430 - loss: 0.1420\n",
      "Epoch 77/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.9469 - loss: 0.1590\n",
      "Epoch 78/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9427 - loss: 0.1265\n",
      "Epoch 79/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - accuracy: 0.9324 - loss: 0.1679\n",
      "Epoch 80/80\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.9841 - loss: 0.0586\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6s/step - accuracy: 0.8822 - loss: 0.5119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4991188049316406, 0.8799999952316284]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import trainer.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_data, train_labels) = data.create_data_with_labels(\"data/train/\")\n",
    "(eval_data, eval_labels) = data.create_data_with_labels(\"data/eval/\")\n",
    "\n",
    "img_shape = train_data.shape[1:]\n",
    "input_layer = tf.keras.Input(shape=img_shape, name='input_image')\n",
    "\n",
    "img_size = [160, 160]\n",
    "ptm = tf.keras.applications.vgg16.VGG16(\n",
    "    input_shape=img_size + [3],\n",
    "    weights='imagenet',\n",
    "    include_top=False)\n",
    "\n",
    "ptm.trainable = False\n",
    "i = ptm.input\n",
    "# x = GlobalMaxPooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(ptm.output)\n",
    "#x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=1000,  # You can tune this value\n",
    "        decay_rate=0.96,   # 4% decrease every 1000 steps\n",
    "        staircase=True)\n",
    "\n",
    "# Compile the model with the learning rate schedule\n",
    "model = tf.keras.models.Model(i, x)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data_augmentation = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,         # Randomly rotate images by 20 degrees\n",
    "    width_shift_range=0.2,     # Randomly shift images horizontally\n",
    "    height_shift_range=0.2,    # Randomly shift images vertically\n",
    "    shear_range=0.2,           # Randomly shear images\n",
    "    zoom_range=0.1,            # Randomly zoom in on images\n",
    "    horizontal_flip=True,      # Randomly flip images horizontally\n",
    "    fill_mode='nearest'        # Fill in new pixels after transformations\n",
    ")\n",
    "\n",
    "# Create augmented training data generator\n",
    "train_gen = data_augmentation.flow(train_data, train_labels, batch_size=10)\n",
    "\n",
    "r = model.fit(train_gen,\n",
    "                 batch_size=10,\n",
    "                 epochs=80)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (5,4))\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['accuracy'], label='accuracy')\n",
    "plt.legend()\n",
    "fig.savefig(\"loss_accuracy_model_data_aug.svg\")\n",
    "\n",
    "model.evaluate(eval_data, eval_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9287c42f-5633-4602-86bc-2b91b7e33bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - accuracy: 0.9032 - loss: 0.3424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35088276863098145, 0.8960000276565552]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_data, eval_labels, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
